{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.SparkSession._\n",
    "import org.apache.spark.sql.{DataFrame,Column,Dataset}\n",
    "import org.json4s._\n",
    "import org.json4s.jackson.JsonMethods._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@718f852b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://ip-172-31-38-146.ec2.internal:4042)\" target=\"new_tab\">Spark UI: application_1552564637687_17772</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1552564637687_17772: Some(http://ip-172-31-38-146.ec2.internal:4042)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = builder.master(\"yarn\").\n",
    "config(\"spark.executor.memory\",\"4G\").\n",
    "config(\"spark.driver.memory\",\"4G\").\n",
    "config(\"spark.cores.max\",\"10\").\n",
    "appName(\"Data Preprocessing\").getOrCreate;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [_c0: int, id: int ... 22 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: int, id: int ... 22 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").\n",
    "option(\"inferSchema\", \"true\").\n",
    "option(\"header\",\"true\").\n",
    "option(\"quote\",\"\\\"\").\n",
    "option(\"delimiter\",\";\").\n",
    "load(\"train2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- Keywords: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- crew: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getNameCollection: org.apache.spark.sql.expressions.UserDefinedFunction\n",
       "getList: (data: org.apache.spark.sql.DataFrame, cols: String, col_temp: String)Array[String]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getNameCollection = udf((entry: String) => {\n",
    "\t// ubah None jadi null\n",
    " \tval clearNone = entry.replaceAll(\"None\", \"null\")\n",
    "\n",
    " \t// jika value json stringnya ' maka harus digantikan dengan \"\n",
    " \tval cleanq = clearNone.replaceAll(\"'\", \"\\\"\")\n",
    "\n",
    "\n",
    " \t// ambil value\n",
    " \ttry {\n",
    " \t\tval parser = parse(cleanq)\n",
    " \t\t def scalaFiles = for {\n",
    "         JObject(child) <- parser\n",
    "         JField(\"name\", JString(name))  <- child\n",
    "       } yield name\n",
    "    \tscalaFiles\n",
    " \t} catch {\n",
    " \t\t case e: Exception => List(null)\n",
    " \t}\n",
    "\n",
    "     })\n",
    "\n",
    "def getList( data: DataFrame, cols: String, col_temp: String) : Array[String] = {\n",
    "      val list_genres_columns = (\n",
    "        data.select(cols)\n",
    "        .withColumn(col_temp,explode(col(cols)))\n",
    "        .select(col_temp).filter($\"$col_temp\".isNotNull)\n",
    "        .distinct.rdd.collect.map(_.getString(0))\n",
    "    )\n",
    "    return list_genres_columns\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_temp = [_c0: int, id: int ... 30 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: int, id: int ... 30 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "var df_temp =  df.\n",
    "withColumn(\"collection\",\n",
    "\t\twhen(\n",
    "              col(\"belongs_to_collection\").isNotNull,\n",
    "              getNameCollection(new Column(\"belongs_to_collection\"))\n",
    "            )\n",
    "\t).\n",
    "withColumn(\"newgenres\",\n",
    "\t\twhen(\n",
    "              col(\"genres\").isNotNull,\n",
    "              getNameCollection(new Column(\"genres\"))\n",
    "            )\n",
    "\t).\n",
    "withColumn(\"newspoken\",\n",
    "\t\twhen(\n",
    "              col(\"spoken_languages\").isNotNull,\n",
    "              getNameCollection(new Column(\"spoken_languages\"))\n",
    "            )\n",
    "\t).\n",
    "withColumn(\"newkeywords\",\n",
    "\t\twhen(\n",
    "              col(\"Keywords\").isNotNull,\n",
    "              getNameCollection(new Column(\"Keywords\"))\n",
    "            )\n",
    "\t).\n",
    "withColumn(\"newcast\",\n",
    "\t\twhen(\n",
    "              col(\"cast\").isNotNull,\n",
    "              getNameCollection(new Column(\"cast\"))\n",
    "            )\n",
    "\t).\n",
    "withColumn(\"newcrew\",\n",
    "\t\twhen(\n",
    "              col(\"crew\").isNotNull,\n",
    "              getNameCollection(new Column(\"crew\"))\n",
    "            )\n",
    "\t).\n",
    "withColumn(\"newproduction_countries\",\n",
    "\t\twhen(\n",
    "              col(\"production_countries\").isNotNull,\n",
    "              getNameCollection(new Column(\"production_countries\"))\n",
    "            )\n",
    "\t).\n",
    "withColumn(\"newproduction_companies\",\n",
    "\t\twhen(\n",
    "              col(\"production_companies\").isNotNull,\n",
    "              getNameCollection(new Column(\"production_companies\"))\n",
    "            )\n",
    ")             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list_genres_columns = Array(Crime, Romance, TV Movie, Thriller, Adventure, Foreign, Drama, War, Documentary, Family, Fantasy, History, Mystery, Animation, Music, Science Fiction, Horror, Western, Comedy, Action)\n",
       "list_spoken_columns = Array(Wolof, 한국어/조선말, Hrvatski, Bahasa indonesia, Gaeilge, Deutsch, Latin, Pусский, Français, Norsk, Somali, پښتو, Kiswahili, हिन्दी, Polski, Română, العربية, বাংলা, isiZulu, Magyar, עִבְרִית, Slovenčina, English, suomi, Tiếng Việt, Español, қазақ, ਪੰਜਾਬੀ, Afrikaans, తెలుగు, Dansk, ภาษาไทย, Český, 广州话 / 廣州話, Eesti, Português, Srpski, Català, Nederlands, Türkçe, فارسی, Український, اردو, 日本語, български език, தமிழ், \"\", Esperanto, shqip, Italiano, euskera, 普通话, ελληνικά, svenska, No Language, Íslenska)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "list_keywords_columns: Arra...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Wolof, 한국어/조선말, Hrvatski, Bahasa indonesia, Gaeilge, Deutsch, Latin, Pусский, Français, Norsk, Somali, پښتو, Kiswahili, हिन्दी, Polski, Română, العربية, বাংলা, isiZulu, Magyar, עִבְרִית, Slovenčina, English, suomi, Tiếng Việt, Español, қазақ, ਪੰਜਾਬੀ, Afrikaans, తెలుగు, Dansk, ภาษาไทย, Český, 广州话 / 廣州話, Eesti, Português, Srpski, Català, Nederlands, Türkçe, فارسی, Український, اردو, 日本語, български език, தமிழ், , Esperanto, shqip, Italiano, euskera, 普通话, ελληνικά, svenska, No Language, Íslenska]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "//df_temp.select(\"newproduction_companies\").filter($\"newproduction_companies\".isNotNull).show()\n",
    "// convert column to list and filtered null value\n",
    "var list_genres_columns = getList(df_temp,\"newgenres\",\"genres\")\n",
    "var list_spoken_columns = getList(df_temp,\"newspoken\",\"spoken\")\n",
    "var list_keywords_columns = getList(df_temp,\"newkeywords\",\"keywords\")\n",
    "var list_cast_columns = getList(df_temp,\"newcast\",\"cast\")\n",
    "var list_crew_columns = getList(df_temp,\"newcrew\",\"crew\")\n",
    "var list_country_columns = getList(df_temp,\"newproduction_countries\",\"prod_countries\")\n",
    "var list_company_columns = getList(df_temp,\"newproduction_companies\",\"prod_s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in thread \"dispatcher-event-loop-3\" Exception in thread \"RemoteBlock-temp-file-clean-thread\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "Exception in thread \"Spark Context Cleaner\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat scala.runtime.ObjectRef.create(ObjectRef.java:22)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:88)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
      "\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: java.lang.OutOfMemoryError\n",
       "Message: GC overhead limit exceeded\n",
       "StackTrace: "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create genres columns from newgenres value\n",
    "for ( genre <- list_genres_columns ){\n",
    "     df_temp = df_temp.\n",
    "    withColumn(\"genre_\"+genre.split(\" \").mkString(\"_\"),when(array_contains(col(\"newgenres\"),genre),1).\n",
    "              otherwise(0))\n",
    "}\n",
    "for ( spoken <- list_spoken_columns ){\n",
    "     df_temp = df_temp.\n",
    "    withColumn(\"spoken_\"+spoken.split(\" \").mkString(\"_\"),when(array_contains(col(\"newspoken\"),spoken),1).\n",
    "              otherwise(0))\n",
    "}\n",
    "for ( keywords <- list_keywords_columns ){\n",
    "     df_temp = df_temp.\n",
    "    withColumn(\"keyword_\"+keywords.split(\" \").mkString(\"_\"),when(array_contains(col(\"newkeywords\"),keywords),1).\n",
    "              otherwise(0))\n",
    "}\n",
    "for ( cast <- list_cast_columns ){\n",
    "     df_temp = df_temp.\n",
    "    withColumn(\"cast_\"+cast.split(\" \").mkString(\"_\"),when(array_contains(col(\"newcast\"),cast),1).\n",
    "              otherwise(0))\n",
    "}\n",
    "for ( crew <- list_crew_columns ){\n",
    "     df_temp = df_temp.\n",
    "    withColumn(\"crew_\"+crew.split(\" \").mkString(\"_\"),when(array_contains(col(\"newcrew\"),crew),1).\n",
    "              otherwise(0))\n",
    "}\n",
    "for ( country <- list_country_columns ){\n",
    "     df_temp = df_temp.\n",
    "    withColumn(\"country_\"+country.split(\" \").mkString(\"_\"),when(array_contains(col(\"newproduction_countries\"),country),1).\n",
    "              otherwise(0))\n",
    "}\n",
    "for ( company <- list_company_columns ){\n",
    "     df_temp = df_temp.\n",
    "    withColumn(\"company_\"+company.split(\" \").mkString(\"_\"),when(array_contains(col(\"newproduction_companies\"),company),1).\n",
    "              otherwise(0))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
